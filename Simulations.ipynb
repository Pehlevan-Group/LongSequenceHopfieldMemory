{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce1f8fe-425d-4c31-af64-ad4ba9394c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "from scipy.special import factorial, factorial2, erfinv, erf\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit, vmap\n",
    "from functools import partial\n",
    "from math import comb\n",
    "\n",
    "import matplotlib as mpl\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "key = jax.random.PRNGKey(2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b6594-b940-4a0d-a750-7d8fb6f7f335",
   "metadata": {},
   "source": [
    "# Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13b19f9-6b46-4889-9352-6e128ef17453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patterns(key, num_neurons, num_patterns):\n",
    "    patterns = random.bernoulli(key, p=0.5, shape=(num_patterns, num_neurons)) \n",
    "    return jnp.where(patterns, 1, -1).astype('float32') # Change True to 1 and False to -1\n",
    "\n",
    "def generate_correlated_patterns(key, eps, num_neurons, num_patterns):\n",
    "    patterns = random.bernoulli(key, p=0.5 + 0.5*eps, shape=(num_patterns, num_neurons)) \n",
    "    return jnp.where(patterns, 1, -1).astype('float32') # Change True to 1 and False to -1\n",
    "\n",
    "def generate_sequences(key, num_neurons, num_patterns, num_sequences=100):\n",
    "    seq_list = []\n",
    "    for s in range(num_sequences):\n",
    "        key, _ = random.split(key)\n",
    "        seq_list += [generate_patterns(key, num_patterns, num_neurons)]\n",
    "    sequences = jnp.stack(seq_list).reshape(num_sequences, num_patterns, num_neurons)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ba823-1fc5-4aaf-8b84-3b6b03a02c24",
   "metadata": {},
   "source": [
    "# Theoretical Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1152e3c-6ef9-4dbd-ae5a-3c15c34d6c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Polynomial DenseNet / MixedNet\n",
    "def theory_PDN_trans(N, d):\n",
    "    return N**d / (2 * factorial2(2*d-1) * jnp.log(N))\n",
    "\n",
    "def theory_PDN_seq(N, d):\n",
    "    return N**d / (2 * (d+1) * factorial2(2*d-1) * jnp.log(N))\n",
    "\n",
    "def gamma(dS, dA, lambd):\n",
    "    if dS < dA:\n",
    "        return factorial2(2*dS-1)\n",
    "    elif dS == dA:\n",
    "        return (lambd**2 + 1)*factorial2(2*dS-1) + 2*lambd*factorial2(dS-1)**2  * (dS % 2 == 0)\n",
    "    else:\n",
    "        return lambd**2 * factorial2(2*dA-1)\n",
    "\n",
    "def theory_PMN_trans(N, dA, dS, lambd):\n",
    "    return (lambd-1)**2 / (2 * gamma(dS, dA, lambd)) * N**(np.min([dS, dA]))/ jnp.log(N)\n",
    "\n",
    "def theory_PMN_seq(N, dA, dS, lambd):\n",
    "    return (lambd-1)**2 / (2 * gamma(dS, dA, lambd) * np.min([dS,dA])) * N**(np.min([dS, dA]))/ jnp.log(N)\n",
    "\n",
    "# Exponential DenseNet / MixedNet\n",
    "beta = jnp.exp(2) / jnp.cosh(2)\n",
    "\n",
    "def theory_EDN_trans(N):\n",
    "    return beta**(N-1) / (2 * jnp.log(N))\n",
    "\n",
    "def theory_EDN_seq(N):\n",
    "    return beta**(N) / (2 * jnp.log(beta) * N)\n",
    "\n",
    "def theory_EMN_trans(N, lambd):\n",
    "    return (lambd-1)**2 / (lambd**2 + 1) * theory_EDN_trans(N)\n",
    "\n",
    "def theory_EMN_seq(N, lambd):\n",
    "    return (lambd-1)**2 / (lambd**2 + 1) * theory_EDN_seq(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0b7610-cb79-4e21-ae2a-fc324554c93a",
   "metadata": {},
   "source": [
    "# Model Definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd11112-c84f-4c6c-aa03-ba3b8c67748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Networks\n",
    "@jit\n",
    "def poly_asym_update(patterns, state, dA): # Update rule for Polynomial DenseNet excluding self-coupling\n",
    "    P, N = patterns.shape\n",
    "    return jnp.einsum('ij,ij->j', jnp.roll(patterns,-1, axis=0), jnp.power( ((patterns@state).reshape(P,1) - (patterns*state)) / (N-1), dA))\n",
    "\n",
    "batched_poly_asym_update = vmap((poly_asym_update), in_axes=(0, 0, None))\n",
    "\n",
    "@jit\n",
    "def poly_sym_update(patterns, state, dS): # Update rule for symmetric term in Exponential MixedNet excluding self-coupling\n",
    "    P, N = patterns.shape\n",
    "    return jnp.einsum('ij,ij->j', patterns, jnp.power( ((patterns@state).reshape(P,1) - (patterns*state)) / (N-1), dS))\n",
    "\n",
    "batched_poly_sym_update = vmap((poly_sym_update), in_axes=(0, 0, None))\n",
    "\n",
    "## Polynomial DenseNet\n",
    "class PDN(object):      \n",
    "    def initialize(self, sequences, tau, dA):\n",
    "        self.sequences = sequences\n",
    "        self.S, self.P, self.N = sequences.shape\n",
    "        self.tau = tau\n",
    "        self.dA = dA\n",
    "\n",
    "    def predict(self, num_timestep):\n",
    "        self.num_timestep = num_timestep\n",
    "        \n",
    "        # Copy to avoid call by reference \n",
    "        self.s_history = np.stack((self.sequences[:,-1,:], self.sequences[:,0,:]))\n",
    "        self.alignment_history = np.zeros((self.num_timestep, self.S, self.P))\n",
    "        \n",
    "        # Define predict list\n",
    "        for t in range(self.num_timestep - 1):            \n",
    "            bitflips = self._run(t)\n",
    "            if bitflips > 0:\n",
    "                return False, jnp.array(self.s_history), jnp.array(self.alignment_history)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        return True, jnp.array(self.s_history), jnp.array(self.alignment_history)\n",
    "        \n",
    "    def _run(self, timestep):\n",
    "        \"\"\"\n",
    "        Synchronous update\n",
    "        \"\"\"\n",
    "        # Initialize in a pattern\n",
    "        t = timestep\n",
    "        states = self.s_history[-1]\n",
    "                \n",
    "        # Update network \n",
    "        h = batched_poly_asym_update(self.sequences, states, self.dA)\n",
    "        states = jnp.sign(h)\n",
    "\n",
    "        # Compute Network Alignment and add to history\n",
    "        alignments = jnp.einsum('ijk,ik->ij', self.sequences, states) / (self.N)\n",
    "        \n",
    "        self.alignment_history[t,:,:] = alignments\n",
    "        self.s_history = np.vstack((self.s_history, states[None]))\n",
    "\n",
    "        # Compute bitflips\n",
    "        bitflips = jnp.sum(jnp.absolute(states - self.sequences[:,t+1])) / 2\n",
    "        return bitflips\n",
    "\n",
    "## Polynomial MixedNet for tau = 1\n",
    "class PMN(object):      \n",
    "    def initialize(self, sequences, lambd, tau, dS, dA):\n",
    "        self.sequences = sequences\n",
    "        self.S, self.P, self.N = sequences.shape\n",
    "        self.Q = self.P - 1\n",
    "        self.lambd = lambd\n",
    "        self.tau = tau\n",
    "        self.dS = dS\n",
    "        self.dA = dA\n",
    "\n",
    "    def predict(self, num_timestep):\n",
    "        self.num_timestep = num_timestep\n",
    "        \n",
    "        # Copy to avoid call by reference \n",
    "        self.s_history = np.stack((self.sequences[:,-1,:], self.sequences[:,0,:]))\n",
    "        self.alignment_history = np.zeros((self.num_timestep, self.S, self.P))\n",
    "        \n",
    "        # Define predict list\n",
    "        for t in range(self.num_timestep - 1):            \n",
    "            bitflips = self._run(t)\n",
    "            if bitflips > 0:\n",
    "                return False, np.array(self.s_history), np.array(self.alignment_history)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        return True, np.array(self.s_history), np.array(self.alignment_history)\n",
    "        \n",
    "    def _run(self, timestep):\n",
    "        \"\"\"\n",
    "        Synchronous update\n",
    "        \"\"\"\n",
    "        # Initialize in a pattern\n",
    "        t = timestep\n",
    "        states = self.s_history[-1]\n",
    "        \n",
    "        # Compute s_avg\n",
    "        # states_avg = jnp.mean(self.s_history[-self.tau:], axis=0)\n",
    "        \n",
    "        # Update network \n",
    "        h_1 = batched_poly_sym_update(self.sequences, states, self.dS)\n",
    "        h_2 = batched_poly_asym_update(self.sequences, states, self.dA)\n",
    "        states = jnp.sign(h_1 + self.lambd * h_2)\n",
    "        \n",
    "        alignments = (jnp.einsum('ijk,ik->ij', self.sequences, states) / self.N)\n",
    "        \n",
    "        self.alignment_history[t,:,:] = alignments\n",
    "        self.s_history = np.vstack((self.s_history, states[None]))\n",
    "        \n",
    "        # Compute bitflips\n",
    "        bitflips = jnp.sum(jnp.absolute(states - self.sequences[:,t+1])) / 2\n",
    "        return bitflips\n",
    "    \n",
    "# Exponential Networks\n",
    "\n",
    "@jit\n",
    "def exp_asym_update(patterns, state): # Update rule for Exponential DenseNet excluding self-coupling\n",
    "    P, N = patterns.shape\n",
    "    return jnp.einsum( 'ij,ij->j', jnp.roll(patterns,-1, axis=0), jnp.exp( ( (patterns@state).reshape(P,1) - (patterns*state) ) - (N-1) ) )\n",
    "\n",
    "batched_exp_asym_update = vmap((exp_asym_update), in_axes=(0, 0))\n",
    "\n",
    "@jit\n",
    "def exp_sym_update(patterns, state): # Update rule for symmetric term in Exponential MixedNet excluding self-coupling\n",
    "    P, N = patterns.shape\n",
    "    return jnp.einsum('ij,ij->j', patterns, jnp.exp( ((patterns@state).reshape(P,1) - (patterns*state)) - (N-1)))\n",
    "\n",
    "batched_exp_sym_update = vmap((exp_sym_update), in_axes=(0, 0))\n",
    "\n",
    "\n",
    "## Exponential DenseNet\n",
    "class EDN(object):      \n",
    "    def initialize(self, sequences, tau):\n",
    "        self.sequences = sequences\n",
    "        self.S, self.P, self.N = sequences.shape\n",
    "        self.lambd = lambd\n",
    "        self.tau = tau\n",
    "\n",
    "    def predict(self, num_timestep):\n",
    "        self.num_timestep = num_timestep\n",
    "        \n",
    "        # Copy to avoid call by reference \n",
    "        self.s_history = np.stack((self.sequences[:,-1,:], self.sequences[:,0,:]))\n",
    "        self.alignment_history = np.zeros((self.num_timestep, self.S, self.P))\n",
    "        \n",
    "        # Define predict list\n",
    "        for t in range(self.num_timestep - 1):   \n",
    "            bitflips = self._run(t)\n",
    "            if bitflips > 0:\n",
    "                return False, np.array(self.s_history), np.array(self.alignment_history)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        return True, np.array(self.s_history), np.array(self.alignment_history)\n",
    "        \n",
    "    def _run(self, timestep):\n",
    "        \"\"\"\n",
    "        Synchronous update\n",
    "        \"\"\"\n",
    "        # Initialize in a pattern\n",
    "        t = timestep\n",
    "        states = self.s_history[-1]\n",
    "\n",
    "        # Update network \n",
    "        h = batched_exp_asym_update(self.sequences, states)\n",
    "        states = jnp.sign(h)\n",
    "\n",
    "        # Compute Network Alignment and add to history\n",
    "        alignments = jnp.einsum('ijk,ik->ij', self.sequences, states) / (self.N)\n",
    "        \n",
    "        self.alignment_history[t,:,:] = alignments\n",
    "        self.s_history = np.vstack((self.s_history, states[None]))\n",
    "\n",
    "        # Compute bitflips\n",
    "        bitflips = jnp.sum(jnp.absolute(states - self.sequences[:,t+1])) / 2\n",
    "        return bitflips\n",
    "    \n",
    "## Exponential MixedNet for tau = 1\n",
    "class EMN(object):      \n",
    "    def initialize(self, sequences, lambd, tau):\n",
    "        self.sequences = sequences\n",
    "        self.S, self.P, self.N = sequences.shape\n",
    "        self.lambd = lambd\n",
    "        self.tau = tau\n",
    "\n",
    "    def predict(self, num_timestep):\n",
    "        self.num_timestep = num_timestep\n",
    "        \n",
    "        # Copy to avoid call by reference \n",
    "        self.s_history = np.stack((self.sequences[:,-1,:], self.sequences[:,0,:]))\n",
    "        self.alignment_history = np.zeros((self.num_timestep, self.S, self.P))\n",
    "        \n",
    "        # Define predict list\n",
    "        for t in range(self.num_timestep - 1):   \n",
    "            bitflips = self._run(t)\n",
    "            if bitflips > 0:\n",
    "                return False, np.array(self.s_history), np.array(self.alignment_history)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        return True, np.array(self.s_history), np.array(self.alignment_history)\n",
    "        \n",
    "    def _run(self, timestep):\n",
    "        \"\"\"\n",
    "        Synchronous update\n",
    "        \"\"\"\n",
    "        # Initialize in a pattern\n",
    "        t = timestep\n",
    "        states = self.s_history[-1]\n",
    "        \n",
    "        # Compute s_avg\n",
    "        # states_avg = jnp.mean(self.s_history[-self.tau:], axis=0)\n",
    "\n",
    "        # Update network \n",
    "        h_1 = batched_exp_sym_update(self.sequences, states) # symmetric term\n",
    "        h_2 = batched_exp_asym_update(self.sequences, states) # asymmetric term\n",
    "        states = jnp.sign(h_1 + self.lambd * h_2)\n",
    "\n",
    "        # Compute Network Alignment and add to history\n",
    "        alignments = jnp.einsum('ijk,ik->ij', self.sequences, states) / (self.N)\n",
    "        \n",
    "        self.alignment_history[t,:,:] = alignments\n",
    "        self.s_history = np.vstack((self.s_history, states[None]))\n",
    "\n",
    "        # Compute bitflips\n",
    "        bitflips = jnp.sum(jnp.absolute(states - self.sequences[:,t+1])) / 2\n",
    "        return bitflips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b42629-bcc5-449c-98aa-5898c265781c",
   "metadata": {},
   "source": [
    "# Transition Simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045f4aad-c431-4830-b02f-feec9a6b6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Networks\n",
    "\n",
    "## Polynomial DenseNet\n",
    "@jit\n",
    "def compute_bitflips_PDN(state_pair, patterns, dA):\n",
    "    state, correct_state = state_pair[0], state_pair[1]\n",
    "    \n",
    "    # Predict Next State Using Update Rule\n",
    "    h = poly_asym_update(patterns, state, dA)\n",
    "    predictedState = jnp.sign(h)\n",
    "\n",
    "    # Return Number of Bit Flips\n",
    "    return jnp.sum(jnp.abs(predictedState - correct_state))/2\n",
    "\n",
    "batched_compute_bitflips_PDN = vmap(compute_bitflips_PDN, in_axes=(0, None, None))\n",
    "\n",
    "def simulate_PDN_transitions(key, N, P, dA):    \n",
    "    while True:\n",
    "        # Generate Random Bernoulli Patterns\n",
    "        key, _ = random.split(key)\n",
    "        patterns = generate_patterns(key, N, P) \n",
    "        \n",
    "        # Pair Current State with Next State\n",
    "        state_pairs = jnp.stack((patterns, jnp.roll(patterns,-1, axis=0)), axis = 1)\n",
    "\n",
    "        # Calculate Number of Bit Flips (errors) in each transition\n",
    "        bitflips_per_pattern = batched_compute_bitflips_PDN(state_pairs, patterns, dA)\n",
    "\n",
    "        # Return Total number of bit flips\n",
    "        total_bitflips = jnp.sum(bitflips_per_pattern)\n",
    "        if total_bitflips == 0:\n",
    "            return P\n",
    "        else:\n",
    "            P = int(0.99*P)\n",
    "\n",
    "## Polynomial MixedNet\n",
    "@jit\n",
    "def compute_bitflips_PMN(state_pair, patterns, dS, dA, lambd):\n",
    "    state, correct_state = state_pair[0], state_pair[1]\n",
    "    \n",
    "    # Predict Next State Using Update Rule\n",
    "    h_1 = poly_sym_update(patterns, state, dS)\n",
    "    h_2 = poly_asym_update(patterns, state, dA)\n",
    "    predictedState = jnp.sign(h_1 + lambd * h_2)\n",
    "\n",
    "    # Return Number of Bit Flips\n",
    "    return jnp.sum(jnp.abs(predictedState - correct_state))/2\n",
    "\n",
    "batched_compute_bitflips_PMN = vmap(compute_bitflips_PMN, in_axes=(0, None, None, None, None))\n",
    "\n",
    "def simulate_PMN_transitions(key, N, P, dA, dS, lambd):    \n",
    "    while True:\n",
    "        # Generate Random Bernoulli Patterns\n",
    "        key, _ = random.split(key)\n",
    "        patterns = generate_patterns(key, N, P) \n",
    "        \n",
    "        # Pair Current State with Next State\n",
    "        state_pairs = jnp.stack((patterns, jnp.roll(patterns,-1, axis=0)), axis = 1)\n",
    "\n",
    "        # Calculate Number of Bit Flips (errors) in each transition\n",
    "        bitflips_per_pattern = batched_compute_bitflips_PMN(state_pairs, patterns, dS, dA, lambd)\n",
    "\n",
    "        # Return Total number of bit flips\n",
    "        total_bitflips = jnp.sum(bitflips_per_pattern)\n",
    "        if total_bitflips == 0:\n",
    "            return P\n",
    "        else:\n",
    "            P = int(0.99*P)\n",
    "\n",
    "## Exponential DenseNet\n",
    "@jit\n",
    "def compute_bitflips_EDN(state_pair, patterns):\n",
    "    state, correct_state = state_pair[0], state_pair[1]\n",
    "    \n",
    "    # Predict Next State Using Update Rule\n",
    "    h = exp_asym_update(patterns, state)\n",
    "    predictedState = jnp.sign(h)\n",
    "\n",
    "    # Return Number of Bit Flips\n",
    "    return jnp.sum(jnp.abs(predictedState - correct_state))/2\n",
    "\n",
    "batched_compute_bitflips_EDN = vmap(compute_bitflips_EDN, in_axes=(0, None))\n",
    "\n",
    "def simulate_EDN_transitions(key, N, P):    \n",
    "    if N == 1:\n",
    "        return 0\n",
    "\n",
    "    while True:\n",
    "        # Generate Random Bernoulli Patterns\n",
    "        key, _ = random.split(key)\n",
    "        patterns = generate_patterns(key, N, P) \n",
    "        \n",
    "        # Pair Current State with Next State\n",
    "        state_pairs = jnp.stack((patterns, jnp.roll(patterns,-1, axis=0)), axis = 1)\n",
    "\n",
    "        # Calculate Number of Bit Flips (errors) in each transition\n",
    "        bitflips_per_pattern = batched_compute_bitflips_EDN(state_pairs, patterns)\n",
    "\n",
    "        # Return Total number of bit flips\n",
    "        total_bitflips = jnp.sum(bitflips_per_pattern)\n",
    "        if total_bitflips == 0:\n",
    "            return P\n",
    "        else:\n",
    "            P = int(0.99*P)\n",
    "\n",
    "## Exponential MixedNet\n",
    "@jit\n",
    "def compute_bitflips_EMN(state_pair, patterns, lambd):\n",
    "    state, correct_state = state_pair[0], state_pair[1]\n",
    "    \n",
    "    # Predict Next State Using Update Rule\n",
    "    h_1 = exp_sym_update(patterns, state)\n",
    "    h_2 = exp_asym_update(patterns, state)\n",
    "    predictedState = jnp.sign(h_1 + lambd * h_2)\n",
    "\n",
    "    # Return Number of Bit Flips\n",
    "    return jnp.sum(jnp.abs(predictedState - correct_state))/2\n",
    "\n",
    "batched_compute_bitflips_EMN = vmap(compute_bitflips_EMN, in_axes=(0, None, None))\n",
    "\n",
    "def simulate_EMN_transitions(key, N, P, lambd):    \n",
    "    if N == 1:\n",
    "        return 0\n",
    "\n",
    "    while True:\n",
    "        # Generate Random Bernoulli Patterns\n",
    "        key, _ = random.split(key)\n",
    "        patterns = generate_patterns(key, N, P) \n",
    "        \n",
    "        # Pair Current State with Next State\n",
    "        state_pairs = jnp.stack((patterns, jnp.roll(patterns,-1, axis=0)), axis = 1)\n",
    "\n",
    "        # Calculate Number of Bit Flips (errors) in each transition\n",
    "        bitflips_per_pattern = batched_compute_bitflips_EMN(state_pairs, patterns, lambd)\n",
    "\n",
    "        # Return Total number of bit flips\n",
    "        total_bitflips = jnp.sum(bitflips_per_pattern)\n",
    "        if total_bitflips == 0:\n",
    "            return P\n",
    "        else:\n",
    "            P = int(0.99*P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9113d-bf6c-4f50-951c-507f92ec2201",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Polynomial DenseNet\n",
    "lambd = 2.5\n",
    "num_trials = 20\n",
    "ds = np.linspace(1,4,4).astype(int)\n",
    "Ns = np.linspace(10,100,10).astype(int)\n",
    "PDN_transition_capacity = np.zeros((len(ds), len(Ns), num_trials))\n",
    "\n",
    "for i_dA, dA in enumerate(ds):\n",
    "    for i_N, N in enumerate(Ns):\n",
    "        display(f'PDN: dA = {dA}, N = {N}, current P = {PDN_transition_capacity[i_dA, i_N]}')\n",
    "        P = round(theory_PDN_trans(N, dA) * 2)\n",
    "        \n",
    "        for T in range(num_trials):\n",
    "            if T > 4:\n",
    "                P = int(np.max(PDN_transition_capacity[i_dA, i_N]) * 1.25)\n",
    "            key, _ = random.split(key)\n",
    "            PDN_transition_capacity[i_dA, i_N, T] = simulate_PDN_transitions(key, N, P, dA)\n",
    "\n",
    "            display(f'PDN: dA = {dA}, N = {N}, T = {T}, final P = {PDN_transition_capacity[i_dA, i_N, T]}')\n",
    "            np.save('final_logs/PDN_transition_capacity', PDN_transition_capacity)            \n",
    "        \n",
    "np.save('final_logs/PDN_transition_capacity', PDN_transition_capacity)\n",
    "\n",
    "# Polynomial MixedNet\n",
    "PMN_transition_capacity = np.zeros((len(ds), len(ds), len(Ns), num_trials))\n",
    "\n",
    "for i_dS, dS in enumerate(ds):\n",
    "    for i_dA, dA in enumerate(ds):\n",
    "        for i_N, N in enumerate(Ns):\n",
    "            display(f'PMN: dS = {dS}, dA = {dA}, N = {N}, current P = {PMN_transition_capacity[i_dS, i_dA, i_N]}')\n",
    "            P = round(theory_PMN_trans(N, dA, dS, lambd) * 2)\n",
    "\n",
    "            for T in range(num_trials):\n",
    "                if T > 4:\n",
    "                    P = int(np.max(PMN_transition_capacity[i_dS, i_dA, i_N]) * 1.25)\n",
    "                key, _ = random.split(key)\n",
    "                PMN_transition_capacity[i_dS, i_dA, i_N, T] = simulate_PMN_transitions(key, N, P, dS, dA, lambd)\n",
    "\n",
    "                display(f'PMN: dA = {dA}, N = {N}, T = {T}, final P = {PMN_transition_capacity[i_dS, i_dA, i_N, T]}')\n",
    "                np.save('final_logs/PMN_transition_capacity', PMN_transition_capacity)            \n",
    "        \n",
    "np.save('final_logs/PMN_transition_capacity', PMN_transition_capacity)\n",
    "\n",
    "# Exponential DenseNet\n",
    "lambd = 2.5\n",
    "num_trials  = 20\n",
    "Ns = np.linspace(1,25,25).astype(int)\n",
    "EDN_transition_capacity = np.zeros((len(Ns), num_trials))\n",
    "\n",
    "for i_N, N in enumerate(Ns):\n",
    "    for T in range(num_trials):\n",
    "        P = round(theory_EDN_trans(N) * 2)\n",
    "        if T > 4:\n",
    "            P = int(jnp.max(EDN_transition_capacity[int(i_N)]) * 1.25)\n",
    "        key, _ = random.split(key)\n",
    "        EDN_transition_capacity[i_N, T] = simulate_EDN_transitions(key, N, P, lambd)\n",
    "        display(f'EDN: dA = {dA}, N = {N}, T = {T}, final P = {EDN_transition_capacity[i_dA, i_N, T]}')\n",
    "        np.save('final_logs/EDN_transition_capacity', EDN_transition_capacity)    \n",
    "\n",
    "np.save('final_logs/EDN_transition_capacity', EDN_transition_capacity)\n",
    "\n",
    "# Exponential MixedNet\n",
    "EMN_transition_capacity = np.zeros((len(Ns), num_trials))\n",
    "\n",
    "for i_N, N in enumerate(Ns):\n",
    "    for T in range(num_trials):\n",
    "        P = round(theory_EMN_trans(N, lambd) * 2)\n",
    "        if T > 4:\n",
    "            P = int(jnp.max(EMN_transition_capacity[int(i_N)]) * 1.25)\n",
    "        key, _ = random.split(key)\n",
    "        EDN_transition_capacity[i_N, T] = simulate_EMN_transitions(key, N, P, lambd)\n",
    "        print(f'Number of Neurons = {N}, Initial Number of Patterns = {int(P)}, Final Number of Patterns = {EMN_transition_capacity[i_N, T]}, Trial = {T}')\n",
    "        np.save('final_logs/EMN_transition_capacity', EMN_transition_capacity)    \n",
    "\n",
    "np.save('final_logs/EMN_transition_capacity', EMN_transition_capacity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c103804d-ef48-4069-bee9-c0c5287611ef",
   "metadata": {},
   "source": [
    "# Sequence Simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6071d39-2135-4459-843c-3525c393f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Polynomial Networks\n",
    "\n",
    "# Simulate Polynomial DenseNet\n",
    "def simulate_PDN_sequences(key, N, tau, dA, P, S):        \n",
    "    while True:\n",
    "        # Generate Random Rademacher Patterns\n",
    "        key, _ = random.split(key)\n",
    "        sequences = generate_sequences(key, N, P, S) \n",
    "\n",
    "        timesteps = P * tau\n",
    "        model = PDN()\n",
    "        model.initialize(sequences, tau, dA)\n",
    "        success, system_states, system_alignments = model.predict(timesteps)\n",
    "\n",
    "        if success == False:\n",
    "            P = int(0.99*P)\n",
    "        else:\n",
    "            return P\n",
    "\n",
    "## Simulate Polynomial MixedNet\n",
    "def simulate_PMN_sequences(key, N, lambd, tau, dS, dA, P):        \n",
    "    while True:\n",
    "        # Generate Random Rademacher Patterns\n",
    "        key, _ = random.split(key)\n",
    "        sequences = generate_sequences(key, N, P, S) \n",
    "\n",
    "        timesteps = P * tau\n",
    "        model = PMN()\n",
    "        model.initialize(sequences, lambd, tau, dS, dA)\n",
    "        success, system_states, system_alignments = model.predict(timesteps)\n",
    "\n",
    "        if success == False:\n",
    "            P = int(0.99*P)\n",
    "        else:\n",
    "            return P\n",
    "\n",
    "# Simulate Exponential Networks\n",
    "\n",
    "## Simulate Exponential DenseNet\n",
    "def simulate_EDN_sequences(key, N, tau, P, S):    \n",
    "    if N == 1:\n",
    "        return 0\n",
    "    \n",
    "    while True:\n",
    "        # Generate Random Rademacher Patterns\n",
    "        key, _ = random.split(key)\n",
    "        sequences = generate_sequences(key, N, P, S) \n",
    "\n",
    "        timesteps = P * tau\n",
    "        model = EDN()\n",
    "        model.initialize(sequences, tau)\n",
    "        success, system_states, system_alignments = model.predict(timesteps)\n",
    "\n",
    "        if success == False:\n",
    "            P = int(0.99*P)\n",
    "        else:\n",
    "            return P\n",
    "        \n",
    "## Simulate Exponential MixedNet\n",
    "def simulate_EMN_sequences(key, N, lambd, tau, P, S):    \n",
    "    if N == 1:\n",
    "        return 0\n",
    "    \n",
    "    while True:\n",
    "        # Generate Random Rademacher Patterns\n",
    "        key, _ = random.split(key)\n",
    "        sequences = generate_sequences(key, N, P, S) \n",
    "\n",
    "        timesteps = P * tau\n",
    "        model = EMN()\n",
    "        model.initialize(sequences, lambd, tau)\n",
    "        success, system_states, system_alignments = model.predict(timesteps)\n",
    "\n",
    "        if success == False:\n",
    "            P = int(0.99*P)\n",
    "        else:\n",
    "            return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca53888-7138-4c84-9454-0e4a2c0b4b97",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_trials = 20\n",
    "lambd = 2.5\n",
    "tau = 1\n",
    "S = 100\n",
    "\n",
    "## Polynomial DenseNet\n",
    "ds = np.linspace(1,4,4).astype('int')\n",
    "Ns = np.linspace(10,100,10).astype('int')\n",
    "PDN_sequence_capacity = np.zeros((len(ds), len(Ns), num_trials))\n",
    "\n",
    "for i_dA, dA in enumerate(ds):\n",
    "    for i_N, N in enumerate(Ns):\n",
    "        display(f'PDN: dA = {dA}, N = {N}, current P = {PDN_sequence_capacity[i_dA, i_N]}')\n",
    "        P = round(theory_PDN_seq(N, dA) * 2)\n",
    "        \n",
    "        for T in range(num_trials):\n",
    "            if T > 4:\n",
    "                P = int(np.max(PDN_sequence_capacity[dA-1, int(N/10)-1]) * 1.25)\n",
    "            key, _ = random.split(key)\n",
    "            PDN_sequence_capacity[i_dA, i_N, T] = simulate_PDN_sequences(key, N, tau, dA, P, S)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            display(f'PDN: dA = {dA}, N = {N}, T = {T}, current P = {PDN_sequence_capacity[i_dA, i_N, T]}')\n",
    "            np.save('final_logs/PDN_sequence_capacity', PDN_sequence_capacity)            \n",
    "        \n",
    "np.save('final_logs/PDN_sequence_capacity', PDN_sequence_capacity)\n",
    "\n",
    "## Polynomial MixedNet\n",
    "ds = np.linspace(1,4,4).astype('int')\n",
    "Ns = np.linspace(10,100,10).astype('int')\n",
    "PMN_sequence_capacity = np.zeros((len(ds), len(ds), len(Ns), num_trials))    \n",
    "\n",
    "for i_dS, dS in enumerate(ds):\n",
    "    for i_dA, dA in enumerate(ds):\n",
    "        for i_N, N in enumerate(Ns):\n",
    "            display(f'PMN: dS = {dS}, dA = {dA}, N = {N}, current P = {PMN_sequence_capacity[i_dS, i_dA, i_N]}')\n",
    "\n",
    "            P = round(theory_PMN_seq(N, dA, dS, lambd) * 2)\n",
    "\n",
    "            for T in range(num_trials):\n",
    "                if T > 4:\n",
    "                    P = int(np.max(PMN_sequence_capacity[dS-1, dA-1, i_N]) * 1.25)\n",
    "                key, _ = random.split(key)\n",
    "                PMN_sequence_capacity[i_dS, i_dA, i_N, T] = simulate_PMN_sequences(key, N, lambd, tau, dS, dA, P)\n",
    "\n",
    "                clear_output(wait=True)\n",
    "                display(f'PMN: dS = {dS}, dA = {dA}, N = {N}, T = {T}, current P = {PMN_sequence_capacity[i_dS, i_dA, i_N, T]}')\n",
    "                np.save('final_logs/PMN_sequence_capacity', PMN_sequence_capacity)            \n",
    "        \n",
    "np.save('final_logs/PMN_sequence_capacity', PMN_sequence_capacity)\n",
    "\n",
    "## Exponential DenseNet\n",
    "Ns = np.linspace(1,25,25).astype('int')\n",
    "EDN_sequence_capacity = np.zeros((len(Ns), num_trials))\n",
    "\n",
    "for i_N, N in enumerate(Ns):\n",
    "    display(f'EDN: N = {N}, current P = {EDN_sequence_capacity[i_N]}')\n",
    "    P = round(theory_EDN_seq(N) * 2)\n",
    "    \n",
    "    for T in range(num_trials):\n",
    "        if T > 4:\n",
    "            P = int(np.max(EDN_sequence_capacity[N-1]) * 1.25)\n",
    "        key, _ = random.split(key)\n",
    "        EDN_sequence_capacity[N-1, T] = simulate_EDN_sequences(key, N, tau, P, S)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(f'EDN: N = {N}, T = {T}, current P = {EDN_sequence_capacity[N-1, T]}')\n",
    "        np.save('final_logs/EDN_sequence_capacity', EDN_sequence_capacity)            \n",
    "        \n",
    "np.save('final_logs/EDN_sequence_capacity', EDN_sequence_capacity)\n",
    "\n",
    "## Exponential MixedNet\n",
    "Ns = np.linspace(1,25,25).astype('int')\n",
    "EMN_sequence_capacity = np.zeros((len(Ns), num_trials))\n",
    "\n",
    "for i_N, N in enumerate(Ns):\n",
    "    display(f'EMN: N = {N}, current P = {EMN_sequence_capacity[i_N]}')\n",
    "    P = round(theory_EMN_seq(N, lambd) * 2)\n",
    "\n",
    "    for T in range(num_trials):\n",
    "        if T > 4:\n",
    "            P = int(np.max(EMN_sequence_capacity[N-1]) * 1.25)\n",
    "        key, _ = random.split(key)\n",
    "        EMN_sequence_capacity[N-1, T] = simulate_EMN_sequences(key, N, lambd, tau, P, S)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(f'EMN: N = {N}, T = {T}, current P = {EMN_sequence_capacity[i_N, T]}')\n",
    "        np.save('final_logs/EMN_sequence_capacity', EMN_sequence_capacity)            \n",
    "        \n",
    "np.save('final_logs/EMN_sequence_capacity', EMN_sequence_capacity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c7c1d0-c413-4ea8-b9ef-232f05aad180",
   "metadata": {},
   "source": [
    "# Generalized Pseudoinverse Rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ea132ce-8898-4584-854f-4aae1fa72e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial DenseNet with GPI\n",
    "@jit\n",
    "def poly_asym_GPI_update(patterns, PI, state, N, dA):\n",
    "    return jnp.diag(jnp.tensordot(jnp.roll(patterns,-1, axis=0), jnp.power( PI @ (((patterns@state).reshape(P,1) - (patterns*state)) / (N-1)), dA), axes = ((0, 0))))\n",
    "\n",
    "class GPI_PDN(object):      \n",
    "    def initialize(self, patterns, tau, dA):\n",
    "        self.patterns = patterns\n",
    "        self.N = patterns.shape[1]\n",
    "        self.P =  patterns.shape[0]\n",
    "        self.tau = tau\n",
    "        self.dA = dA\n",
    "        O = jnp.tensordot(patterns.astype(float), patterns, axes = ((1, 1))) / N \n",
    "        self.PI = jnp.linalg.pinv(O.astype(float), hermitian=True)\n",
    "        \n",
    "\n",
    "\n",
    "    def predict(self, num_timestep=1):\n",
    "        self.num_timestep = num_timestep\n",
    "        \n",
    "        # Copy to avoid call by reference \n",
    "        self.s_history = np.vstack((np.tile(self.patterns[-1], (self.tau,1)), self.patterns[0]))\n",
    "        self.alignment_history = np.zeros((self.P, self.num_timestep))\n",
    "        \n",
    "        # Define predict list\n",
    "        for t in range(self.num_timestep - 1):            \n",
    "            bitflips = self._run(t)\n",
    "            if bitflips > 0:\n",
    "                return False, np.array(self.s_history), np.array(self.alignment_history)\n",
    "\n",
    "        return True, np.array(self.s_history), np.array(self.alignment_history)\n",
    "        \n",
    "    def _run(self, timestep):\n",
    "        \"\"\"\n",
    "        Synchronous update\n",
    "        \"\"\"\n",
    "        # Initialize in a pattern\n",
    "        t = timestep\n",
    "        s = self.s_history[-1]\n",
    "        \n",
    "        # Update network \n",
    "        h = poly_asym_GPI_update(self.patterns, self.PI, s, self.N, self.dA)\n",
    "        s = jnp.sign(h)\n",
    "\n",
    "        # Compute Network Alignment and add to history\n",
    "        alignment = np.tensordot(self.patterns, s, 1) / self.N\n",
    "        self.alignment_history[:,t] = alignment\n",
    "        self.s_history = np.vstack((self.s_history,s))        \n",
    "        \n",
    "        # Compute bitflips\n",
    "        bitflips = jnp.sum(jnp.absolute(s - self.patterns[timestep+1])) / 2\n",
    "        return bitflips\n",
    "\n",
    "# Exponential DenseNet with GPI\n",
    "@jit\n",
    "def exp_asym_GPI_update(patterns, PI, state, N):\n",
    "    return jnp.diag(jnp.tensordot(jnp.roll(patterns,-1, axis=0), jnp.exp( PI @ ((patterns@state).reshape(P,1) - (patterns*state) - (N-1))), axes = ((0, 0))))\n",
    "\n",
    "class GPI_EDN(object):      \n",
    "    def initialize(self, patterns, tau):\n",
    "        self.patterns = patterns\n",
    "        self.N = patterns.shape[1]\n",
    "        self.P =  patterns.shape[0]\n",
    "        self.tau = tau\n",
    "        O = jnp.tensordot(patterns.astype(float), patterns, axes = ((1, 1))) / N\n",
    "        self.PI = jnp.linalg.pinv(O.astype(float), hermitian=True)\n",
    "        x = self.PI\n",
    "\n",
    "    def predict(self, num_timestep=1):\n",
    "        self.num_timestep = num_timestep\n",
    "        \n",
    "        # Copy to avoid call by reference \n",
    "        self.s_history = np.vstack((np.tile(self.patterns[-1], (self.tau,1)), self.patterns[0]))\n",
    "        self.alignment_history = np.zeros((self.P, self.num_timestep))\n",
    "        \n",
    "        # Define predict list\n",
    "        for t in range(self.num_timestep - 1):            \n",
    "            bitflips = self._run(t)\n",
    "            if bitflips > 0:\n",
    "                return False, np.array(self.s_history), np.array(self.alignment_history)\n",
    "\n",
    "        return True, np.array(self.s_history), np.array(self.alignment_history)\n",
    "  \n",
    "        \n",
    "    def _run(self, timestep):\n",
    "        \"\"\"\n",
    "        Synchronous update\n",
    "        \"\"\"\n",
    "        # Initialize in a pattern\n",
    "        t = timestep\n",
    "        s = self.s_history[-1]\n",
    "        \n",
    "        # Update network \n",
    "        h_2 = exp_asym_GPI_update(self.patterns, self.PI, s, self.N)\n",
    "        s = jnp.sign(h_2)\n",
    "\n",
    "        # Compute Network Alignment and add to history\n",
    "        alignment = np.tensordot(self.patterns, s, 1) / self.N\n",
    "        self.alignment_history[:,t] = alignment\n",
    "        self.s_history = np.vstack((self.s_history,s))        \n",
    "        \n",
    "        # Compute bitflips\n",
    "        bitflips = jnp.sum(jnp.absolute(s - self.patterns[timestep+1])) / 2\n",
    "        return bitflips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c5d5f-9014-43e3-98a9-e534c9a15554",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPI_PDN\n",
    "N = 100\n",
    "tau = 1\n",
    "num_trials = 20\n",
    "eps = np.linspace(0, 0.95, 20)\n",
    "ds = np.linspace(1, 4, 4).astype(int)\n",
    "GPI_PDN_capacity = np.zeros((len(ds), len(eps), num_trials))\n",
    "\n",
    "\n",
    "for i_d, d in enumerate(ds):\n",
    "    for i_e, e in enumerate(eps):\n",
    "\n",
    "        display(f'GPI_PDN: N = {N}, d = {d}, eps = {e:.2f}, current P = {GPI_PDN_capacity[i_d, i_e]}')\n",
    "        P = round(theory_PDN_seq(N, d) * 20)\n",
    "        \n",
    "        for T in range(num_trials):\n",
    "            if T > 4:\n",
    "                P = int(jnp.max(GPI_PDN_capacity[i_d, i_e])*1.25)\n",
    "            \n",
    "            while True:\n",
    "                key, _ = random.split(key)\n",
    "                timesteps = P * tau\n",
    "                patterns = generate_correlated_patterns(key, e, N, P)\n",
    "                            \n",
    "                model = GPI_PDN()\n",
    "                model.initialize(patterns, tau, d)\n",
    "                success, system_states, system_alignments = model.predict(timesteps)\n",
    "\n",
    "                if success == True:\n",
    "                    GPI_PDN_capacity[i_d, i_e, T] = system_alignments.shape[0]\n",
    "                    \n",
    "                    clear_output(wait=True)\n",
    "                    display(f'End: d = {d}, N = {N}, eps = {e:.2f}, T = {T}, final P = {GPI_PDN_capacity[i_d, i_e, T]}')\n",
    "                    \n",
    "                    # Save results\n",
    "                    np.save('final_logs/GPI_PDN_sequence_capacity', GPI_PDN_capacity)            \n",
    "                    break \n",
    "\n",
    "                else:\n",
    "                    P = int(P*0.99)\n",
    "                    \n",
    "                    \n",
    "# GPI_EDN\n",
    "N = 20\n",
    "tau = 1\n",
    "num_trials = 20\n",
    "eps = np.linspace(0, 0.95, 20)\n",
    "GPI_EDN_capacity = np.zeros((len(eps), num_trials))\n",
    "\n",
    "\n",
    "\n",
    "for i_e, e in enumerate(eps):\n",
    "    display(f'GPI_EDN: N = {N}, eps = {e:.2f}, current P = {GPI_EDN_capacity[i_e]}')\n",
    "    P = round(theory_EDN_seq(N) * 1)\n",
    "\n",
    "    for T in range(num_trials):\n",
    "        if T > 4:\n",
    "            P = int(jnp.max(GPI_EDN_capacity[i_e])*1.25)\n",
    "\n",
    "        while True:\n",
    "            key, _ = random.split(key)\n",
    "            timesteps = P * tau\n",
    "            patterns = generate_correlated_patterns(key, e, N, P)\n",
    "\n",
    "            model = GPI_EDN()\n",
    "            model.initialize(patterns, tau)\n",
    "            success, system_states, system_alignments = model.predict(timesteps)\n",
    "\n",
    "            if success == True:\n",
    "                GPI_EDN_capacity[i_e, T] = system_alignments.shape[0]\n",
    "\n",
    "                clear_output(wait=True)\n",
    "                display(f'End: d = {d}, N = {N}, eps = {e:.2f}, T = {T}, final P = {GPI_EDN_capacity[i_e, T]}')\n",
    "\n",
    "                # Save results\n",
    "                np.save('final_logs/GPI_EDN_sequence_capacity', GPI_EDN_capacity)            \n",
    "                break \n",
    "\n",
    "            else:\n",
    "                P = int(P*0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018177a-1991-44af-b73a-1d248bcc3398",
   "metadata": {},
   "source": [
    "# Maximal Degree for Polynomial DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3052d2f-0bfb-434f-90b3-6eadb5e9494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_d_trans(N, d):\n",
    "    while True:\n",
    "        cond = (N**d / np.log(N)) < (2 * factorial2(2*d-1)) \n",
    "\n",
    "        if cond:\n",
    "            d = int(0.99*d)\n",
    "        else:\n",
    "            return d\n",
    "        \n",
    "def max_d_seq(N, d):\n",
    "    while True:\n",
    "        cond = (N**d / np.log(N)) < (2 * (d+1) * factorial2(2*d-1)) \n",
    "\n",
    "        if cond:\n",
    "            d = int(0.99*d)\n",
    "        else:\n",
    "            return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd19d327-5711-48d4-b581-cda638c670d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ns = [10, 15, 20]\n",
    "\n",
    "num_trials = 20\n",
    "ds = list(range(1, 2*max_d_trans(20,100)))\n",
    "max_degree = np.zeros((len(Ns), len(ds), num_trials))\n",
    "\n",
    "for i_N, N in enumerate(Ns):\n",
    "    ds = list(range(1, 2*max_d_trans(N,100)))\n",
    "    for i_d, d in enumerate(ds):\n",
    "        P = round(theory_PDN_trans(N, d) * 2.5)\n",
    "        for T in range(num_trials):            \n",
    "            key, _ = random.split(key)\n",
    "            max_degree[i_N, i_d, T] = simulate_PDN_transitions(key, N, P, d)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            display(f'PAHN: N = {N}, d = {d}, T = {T}, current P = {max_degree[i_N, i_d, T]}')\n",
    "    np.save(f'final_logs/max_degree_capacity', max_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e177b71e-b746-4904-84e1-ab2e9073af65",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MNIST Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a17c4b4-3f07-41bc-a5eb-522dbee33b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tqdm import tqdm\n",
    "import tqdm.notebook as tq\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.special import factorial2, erfinv, comb\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit, vmap, pmap\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "key = random.PRNGKey(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "213501b5-e858-493e-86b4-d5067ee76b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import MNIST dataset and convert it to Black and White for Binary Image Sequence Recall\n",
    "np.random.seed(2023)\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "nclasses = np.unique(train_y).size\n",
    "threshold = 125\n",
    "def shapex(X):\n",
    "    XX = np.empty_like(X)\n",
    "    XX[X< threshold] = 0\n",
    "    XX[X>=threshold] = 1\n",
    "    XX = XX.reshape(*XX.shape, 1) \n",
    "    return XX\n",
    "train_X = shapex(train_X)\n",
    "test_X = shapex(test_X)\n",
    "train_y = to_categorical(train_y)\n",
    "test_y = to_categorical(test_y)\n",
    "\n",
    "# Reshape to form a sequence of images in order 0 -> 9 and then repeating\n",
    "num_samples = 2500\n",
    "numbers = []\n",
    "numbers += [train_X[np.where(train_y[:,i] == 1)][:2500] for i in range(10)]\n",
    "number_array = np.array(numbers)\n",
    "\n",
    "np_seq = np.empty(((number_array.shape[0] * number_array.shape[1], number_array.shape[2], number_array.shape[3], number_array.shape[4])), dtype=number_array.dtype)\n",
    "for i in range(10):\n",
    "    np_seq[i::10] = number_array[i]\n",
    "\n",
    "images = jnp.where(np_seq.reshape(2500 * 10, 28*28), 1, -1).astype('int16')\n",
    "image_pairs = jnp.stack((images, jnp.roll(images,-1, axis=0)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "736e6daf-980f-4281-9431-d6da136d40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Update Rules\n",
    "@jit\n",
    "def predict_image_poly(state_pair, patterns, d = 10):\n",
    "    N = patterns.shape[1]\n",
    "    state, correct_state = state_pair[0], state_pair[1]\n",
    "    \n",
    "    # Predict Next State Using Update Rule\n",
    "    h_2 = jnp.tensordot(jnp.roll(patterns,-1, axis=0), jnp.power(patterns @ state / N, d), axes = ((0), (0))) \n",
    "    predicted_state = jnp.sign(h_2)\n",
    "\n",
    "    # Return Number of Bit Flips\n",
    "    return predicted_state\n",
    "    # return predicted_state, jnp.sum(jnp.abs(predicted_state - correct_state))/2\n",
    "\n",
    "batched_predict_image_poly = vmap(predict_image_poly, in_axes=(0, None, None))\n",
    "\n",
    "@jit\n",
    "def predict_image_exp(state_pair, patterns):\n",
    "    N = patterns.shape[1]\n",
    "    state, correct_state = state_pair[0], state_pair[1]\n",
    "    \n",
    "    # Predict Next State Using Update Rule\n",
    "    h_2 = jnp.tensordot(jnp.roll(patterns,-1, axis=0), jnp.exp(patterns @ state - N), axes = ((0), (0))) \n",
    "    predicted_state = jnp.sign(h_2)\n",
    "\n",
    "    # Return Number of Bit Flips\n",
    "    return predicted_state\n",
    "    # return predicted_state, jnp.sum(jnp.abs(predicted_state - correct_state))/2\n",
    "\n",
    "batched_predict_image_exp = vmap(predict_image_exp, in_axes=(0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e095e-2419-4ae3-99f6-c8cea02ea0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_images = image_pairs[:,1,:]\n",
    "ds = [1, 5, 25]\n",
    "ts = [0, 101, 202, 303]\n",
    "fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(20, 18))\n",
    "for t_i, t in enumerate(ts):\n",
    "    axes[t_i, 0].imshow(true_images[t].reshape(28,28), cmap='Greys')\n",
    "    axes[t_i, 0].tick_params(left = False, right = False , labelleft = False, labelbottom = False, bottom = False)\n",
    "    if t_i == 0:\n",
    "        axes[t_i, 0].set_title('True', fontsize=40)\n",
    "\n",
    "poly_predicted_images = [batched_predict_image_poly(image_pairs, images, d) for d in ds]\n",
    "for d_i, d in enumerate(ds):\n",
    "    predicted_images = poly_predicted_images[d_i]\n",
    "    print(f'Degree = {d}')\n",
    "    for t_i, t in enumerate(ts):\n",
    "        axes[t_i, d_i+1].imshow(predicted_images[t].reshape(28,28), cmap='Greys')\n",
    "        axes[t_i, d_i+1].tick_params(left = False, right = False , labelleft = False, labelbottom = False, bottom = False)\n",
    "        if t_i == 0:\n",
    "            axes[t_i, d_i+1].set_title(f'Poly: $d = {d}$', fontsize=40)\n",
    "            if d == 1:\n",
    "                axes[t_i, d_i+1].set_title(f'SeqNet', fontsize=40)\n",
    "\n",
    "\n",
    "print(f'Exp')\n",
    "exp_predicted_images = batched_predict_image_exp(image_pairs, images)\n",
    "for t_i, t in enumerate(ts):\n",
    "    axes[t_i, -1].imshow(exp_predicted_images[t].reshape(28,28), cmap='Greys')\n",
    "    axes[t_i, -1].tick_params(left = False, right = False , labelleft = False, labelbottom = False, bottom = False)\n",
    "    if t_i == 0:\n",
    "        axes[t_i, -1].set_title(f'Exp', fontsize=40)\n",
    "\n",
    "fig.suptitle('Image Sequence Recall', fontsize=35)\n",
    "fig.tight_layout()\n",
    "fig.savefig('plots/Image_Sequence.pdf', format = 'pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654b98a8-361a-45aa-8df8-89cfdd838edf",
   "metadata": {},
   "source": [
    "# Excess Kurtosis Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc05f92b-6866-4961-9f55-8b405a9f5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis\n",
    "\n",
    "# Function for calculating the xtalk_all and all_stored values\n",
    "def calculate_values(ind_n, ind_p, n_list, p_list, n_rep):\n",
    "    xi1 = 2 * (np.random.rand(n_rep, p_list[ind_p] - 1) > 0.5) - 1\n",
    "    bin1 = np.random.binomial(n_list[ind_n] - 1, 0.5, (n_rep, p_list[ind_p] - 1))\n",
    "\n",
    "    xtalk = np.sum(xi1 * np.exp(2 * bin1 - 2 * (n_list[ind_n] - 1)), axis=1)\n",
    "    return xtalk, xtalk > -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff89053-fc97-46a6-9667-8a764a67d98c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_list = np.arange(10, 21)\n",
    "p_list = np.floor(10 ** np.arange(2, 4.25, 0.25)).astype(int)\n",
    "n_rep = 50000\n",
    "\n",
    "b = np.exp(2) / np.cosh(2)\n",
    "\n",
    "xtalk_all = np.zeros((len(n_list), len(p_list), n_rep))\n",
    "all_stored = np.zeros((len(n_list), len(p_list), n_rep))\n",
    "\n",
    "for ind_n in range(len(n_list)):\n",
    "    for ind_p in range(len(p_list)):\n",
    "        xtalk_all[ind_n, ind_p], all_stored[ind_n, ind_p] = calculate_values(ind_n, ind_p, n_list, p_list, n_rep)\n",
    "        np.save('final_logs/edn_crosstalk', xtalk_all)\n",
    "np.save('final_logs/edn_crosstalk', xtalk_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3339c331-d6ee-4290-a7c2-19813b7e4482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
